{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIA_PATH = os.path.join('/media', 'disk2', 'amaltsev', 'car_lp_generator')\n",
    "\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_new_path = os.path.join(MEDIA_PATH, 'rendered_new')\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([os.path.join(rendered_new_path, img) for img in sorted(os.listdir(rendered_new_path))[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_image_test(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "#     image = tf.image.resize(image, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(load_preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(MEDIA_PATH, 'checkpoints', 'train')\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing car_0002_P313OK11_.jpg\n",
      "(1014, 2000, 3)\n",
      "672 743 1488 1583\n",
      "processing car_0007_K089YP357.jpg\n",
      "(1073, 2000, 3)\n",
      "512 591 368 503\n",
      "processing car_0009_B683XE197.jpg\n",
      "(1021, 2000, 3)\n",
      "512 591 328 455\n",
      "processing car_0010_B080ME35_.jpg\n",
      "(900, 1200, 3)\n",
      "552 599 496 567\n",
      "processing car_0011_T446MK15_.jpg\n",
      "(1004, 2000, 3)\n",
      "632 703 160 223\n",
      "processing car_0015_P757KX340.jpg\n",
      "(900, 1200, 3)\n",
      "560 591 480 543\n",
      "processing car_0016_K773BY797.jpg\n",
      "(1098, 2000, 3)\n",
      "768 847 456 599\n",
      "processing car_0020_E555MK177.jpg\n",
      "(1210, 2000, 3)\n",
      "768 847 648 799\n",
      "processing car_0021_O878KT75_.jpg\n",
      "(818, 1222, 3)\n",
      "408 479 720 831\n",
      "processing car_0022_X567PA39_.jpg\n",
      "(900, 1200, 3)\n",
      "536 567 464 519\n",
      "processing car_0023_C382MK197.jpg\n",
      "(1062, 2000, 3)\n",
      "664 735 392 503\n",
      "processing car_0026_T411TO170.jpg\n",
      "(1307, 1912, 3)\n",
      "712 791 1312 1407\n",
      "processing car_0031_M241OC197.jpg\n",
      "(1089, 2000, 3)\n",
      "712 799 344 479\n",
      "processing car_0034_X296KY749.jpg\n",
      "(740, 1216, 3)\n",
      "488 535 248 319\n",
      "processing car_0037_M355CP370.jpg\n",
      "(1103, 2000, 3)\n",
      "680 775 416 559\n",
      "processing car_0040_M860HO197.jpg\n",
      "(1109, 2000, 3)\n",
      "496 599 472 631\n",
      "processing car_0047_B316XB197.jpg\n",
      "(1097, 2000, 3)\n",
      "696 791 328 471\n",
      "processing car_0049_B620PO16_.jpg\n",
      "(1169, 2000, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cead6fc19099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mh1_bound\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mh1_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_iterator = iter(dataset)\n",
    "\n",
    "for img_name in sorted(os.listdir(rendered_new_path))[1:]:\n",
    "    \n",
    "#     if os.path.exists(os.path.join(MEDIA_PATH, 'final', img_name)):\n",
    "#         continue\n",
    "    \n",
    "    print('processing', img_name)\n",
    "    \n",
    "    image = next(dataset_iterator)\n",
    "    \n",
    "    new_mask = cv.imread(os.path.join(MEDIA_PATH, 'new_masks', img_name))\n",
    "    h1_bound, h2_bound, w1_bound, w2_bound = -1, -1, new_mask.shape[1], -1\n",
    "    print(new_mask.shape)\n",
    "    \n",
    "    for i in range(new_mask.shape[0]):\n",
    "        for j in range(new_mask.shape[1]):\n",
    "            if (new_mask[i][j] > np.array([200, 200, 200])).all():\n",
    "                if h1_bound == -1:\n",
    "                    h1_bound = i\n",
    "                \n",
    "                h2_bound = i\n",
    "                \n",
    "                if j < w1_bound:\n",
    "                    w1_bound = j\n",
    "                \n",
    "                if j > w2_bound:\n",
    "                    w2_bound = j\n",
    "    \n",
    "    print(h1_bound, h2_bound, w1_bound, w2_bound)\n",
    "    \n",
    "    cropped = image[:, h1_bound : h2_bound, w1_bound : w2_bound, :]\n",
    "    cropped = tf.image.resize(cropped, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    transferred = generator_f(cropped)[0]\n",
    "    transferred = (transferred + 1) * 127.5\n",
    "    transferred = tf.cast(transferred, tf.uint8)\n",
    "    tf.io.write_file(os.path.join(MEDIA_PATH, 'transferred', img_name), tf.io.encode_jpeg(transferred))\n",
    "    \n",
    "    transferred = tf.image.resize(transferred, [h2_bound - h1_bound + 1, w2_bound - w1_bound + 1], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    removed_name = img_name.split('.')[0][:-10] + '.jpg'\n",
    "    final = cv.imread(os.path.join(MEDIA_PATH, 'removed_plates', removed_name))\n",
    "    \n",
    "    for i in range(h1_bound, h2_bound + 1):\n",
    "        for j in range(w1_bound, w2_bound + 1):\n",
    "            if (new_mask[i][j] > np.array([200, 200, 200])).all():\n",
    "                final[i][j] = transferred[i - h1_bound][j - w1_bound]\n",
    "    \n",
    "    cv.imwrite(os.path.join(MEDIA_PATH, 'final', img_name), final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
