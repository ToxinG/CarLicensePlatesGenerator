{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIA_PATH = os.path.join('/media', 'disk2', 'amaltsev', 'car_lp_generator')\n",
    "\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_new_path = os.path.join(MEDIA_PATH, 'style_dst_sq')\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([os.path.join(rendered_new_path, img) for img in sorted(os.listdir(rendered_new_path))[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_image_test(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "#     image = tf.image.resize(image, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    image = normalize(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(load_preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(MEDIA_PATH, 'checkpoints', 'train')\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing car_0006.jpg\n",
      "0\n",
      "0.1669766902923584\n",
      "processing car_0008.jpg\n",
      "processing car_0009.jpg\n",
      "processing car_0010.jpg\n",
      "processing car_0012.jpg\n",
      "processing car_0013.jpg\n",
      "processing car_0015.jpg\n",
      "processing car_0016.jpg\n",
      "processing car_0018.jpg\n",
      "processing car_0021.jpg\n",
      "processing car_0022.jpg\n",
      "processing car_0023.jpg\n",
      "processing car_0027.jpg\n",
      "processing car_0028.jpg\n",
      "processing car_0030.jpg\n",
      "processing car_0031.jpg\n",
      "processing car_0032.jpg\n",
      "processing car_0035.jpg\n",
      "processing car_0037.jpg\n",
      "processing car_0039.jpg\n",
      "processing car_0040.jpg\n",
      "processing car_0041.jpg\n",
      "processing car_0042.jpg\n",
      "processing car_0046.jpg\n",
      "processing car_0047.jpg\n",
      "processing car_0049.jpg\n",
      "processing car_0050.jpg\n",
      "processing car_0054.jpg\n",
      "processing car_0059.jpg\n",
      "processing car_0060.jpg\n",
      "processing car_0061.jpg\n",
      "processing car_0064.jpg\n",
      "processing car_0065.jpg\n",
      "processing car_0066.jpg\n",
      "processing car_0067.jpg\n",
      "processing car_0068.jpg\n",
      "processing car_0070.jpg\n",
      "processing car_0073.jpg\n",
      "processing car_0075.jpg\n",
      "processing car_0076.jpg\n",
      "processing car_0078.jpg\n",
      "processing car_0080.jpg\n",
      "processing car_0081.jpg\n",
      "processing car_0083.jpg\n",
      "processing car_0085.jpg\n",
      "processing car_0091.jpg\n",
      "processing car_0092.jpg\n",
      "processing car_0093.jpg\n",
      "processing car_0094.jpg\n",
      "processing car_0095.jpg\n",
      "processing car_0097.jpg\n",
      "processing car_0099.jpg\n",
      "processing car_0101.jpg\n",
      "processing car_0102.jpg\n",
      "processing car_0104.jpg\n",
      "processing car_0108.jpg\n",
      "processing car_0109.jpg\n",
      "processing car_0110.jpg\n",
      "processing car_0111.jpg\n",
      "processing car_0113.jpg\n",
      "processing car_0116.jpg\n",
      "processing car_0117.jpg\n",
      "processing car_0118.jpg\n",
      "processing car_0119.jpg\n",
      "processing car_0121.jpg\n",
      "processing car_0122.jpg\n",
      "processing car_0123.jpg\n",
      "processing car_0125.jpg\n",
      "processing car_0126.jpg\n",
      "processing car_0127.jpg\n",
      "processing car_0128.jpg\n",
      "processing car_0129.jpg\n",
      "processing car_0130.jpg\n",
      "processing car_0131.jpg\n",
      "processing car_0132.jpg\n",
      "processing car_0134.jpg\n",
      "processing car_0136.jpg\n",
      "processing car_0138.jpg\n",
      "processing car_0139.jpg\n",
      "processing car_0140.jpg\n",
      "processing car_0142.jpg\n",
      "processing car_0143.jpg\n"
     ]
    }
   ],
   "source": [
    "dataset_iterator = iter(dataset)\n",
    "\n",
    "i = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for img_name in sorted(os.listdir(rendered_new_path))[1:]:\n",
    "    \n",
    "#     print('processing', img_name)\n",
    "    \n",
    "    image = next(dataset_iterator)\n",
    "    \n",
    "#     if os.path.exists(os.path.join(MEDIA_PATH, 'final', img_name)):\n",
    "#         continue\n",
    "    \n",
    "#     new_mask = cv.imread(os.path.join(MEDIA_PATH, 'new_masks', img_name))\n",
    "#     h1_bound, h2_bound, w1_bound, w2_bound = -1, -1, new_mask.shape[1], -1\n",
    "#     print(new_mask.shape)\n",
    "    \n",
    "#     for i in range(new_mask.shape[0]):\n",
    "#         for j in range(new_mask.shape[1]):\n",
    "#             if (new_mask[i][j] > np.array([200, 200, 200])).all():\n",
    "#                 if h1_bound == -1:\n",
    "#                     h1_bound = i\n",
    "                \n",
    "#                 h2_bound = i\n",
    "                \n",
    "#                 if j < w1_bound:\n",
    "#                     w1_bound = j\n",
    "                \n",
    "#                 if j > w2_bound:\n",
    "#                     w2_bound = j\n",
    "    \n",
    "#     print(h1_bound, h2_bound, w1_bound, w2_bound)\n",
    "    \n",
    "#     cropped = image[:, h1_bound : h2_bound, w1_bound : w2_bound, :]\n",
    "    cropped = tf.image.resize(image, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "    transferred = generator_f(cropped)[0]\n",
    "    transferred = (transferred + 1) * 127.5\n",
    "    transferred = tf.cast(transferred, tf.uint8)\n",
    "    tf.io.write_file(os.path.join(MEDIA_PATH, 'transferred_cyclegan', img_name), tf.io.encode_jpeg(transferred))\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        print(time.time() - start_time)\n",
    "    i += 1\n",
    "    \n",
    "#     transferred = tf.image.resize(transferred, [h2_bound - h1_bound + 1, w2_bound - w1_bound + 1], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    \n",
    "#     removed_name = img_name.split('.')[0][:-10] + '.jpg'\n",
    "#     final = cv.imread(os.path.join(MEDIA_PATH, 'removed_plates', removed_name))\n",
    "    \n",
    "#     for i in range(h1_bound, h2_bound + 1):\n",
    "#         for j in range(w1_bound, w2_bound + 1):\n",
    "#             if (new_mask[i][j] > np.array([200, 200, 200])).all():\n",
    "#                 final[i][j] = transferred[i - h1_bound][j - w1_bound]\n",
    "    \n",
    "#     cv.imwrite(os.path.join(MEDIA_PATH, 'final', img_name), final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
